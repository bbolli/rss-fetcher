#!/usr/bin/env python

# fetches an RSS feed with enclosures, and submits any torrents found
# to the Transmission bittorrent client.

import sys, os, re, socket, httplib, urllib, time, pprint
import feedparser


class RSSFetcher:

    def __init__(self, opts):
        self.opts = opts
        self.db_file = self.path('rss-latest.py')
        self.db = {}
        self.url = None
        self.log_started = False
        try:
            db = open(self.db_file).read()
        except (IOError, OSError):
            db = '{}'
        try:
            self.db = eval(db, {}, {})
        except Exception, e:
            self.log(repr(e))
            sys.exit(2)

    def __del__(self):
        self.close()

    def close(self):
        if not self.opts.dry_run and self.db_file:
            open(self.db_file, 'w').write(repr(self.db).replace('), ', '),\n ') + '\n')
            self.db_file = None

    def log(self, msg, level=0):
        if level > self.opts.debug:
            return
        if not self.log_started:
            print time.asctime()
            if self.url:
                print self.url
            self.log_started = True
        if type(msg) in (str, unicode):
            print msg
        else:
            pprint.pprint(msg)

    def path(self, *suffixes):
        return os.path.join(self.opts.dest_dir, *suffixes)

    def fetch(self, url, patterns=[]):
        self.latest_updated = self.db.setdefault(url, 0)
        self.url = url
        feed = feedparser.parse(url)
        self.log(feed, 3)
        if not hasattr(feed, 'status'):
            self.log('! feed object has no status attribute:', 1)
            return self.log(feed, 1)
        if feed.status == 301:      # permanently redirected
            self.log('* Redirect: %s\n  ==>       %s' % (url, feed.href))
        elif feed.status == 410:    # gone
            self.log('! Gone: %s' % url)
            if url in self.db:
                del self.db[url]
            return
        elif feed.status != 200:
            self.log('* Status: %d' % feed.status)
        self.new_latest = self.latest_updated
        if patterns:
            entries = [e for e in feed.entries for p in patterns if re.search(p, e.title)]
        else:
            entries = feed.entries
        for entry in entries:
            self.get_entry(entry)
        self.db[url] = self.new_latest
        self.url = None

    def get_entry(self, entry):
        self.log(entry, 2)
        tm = time.mktime(entry.updated_parsed)
        if not self.opts.force and tm <= self.latest_updated:
            return self.log('! Old entry, already looked at earlier: %s' % entry.title, 1)
        if self.new_latest < tm:
            self.log(entry.title)
            self.new_latest = tm
            self.log('* Updating latest date to %s' % time.ctime(tm), 1)
            for enclosure in [
                e for e in entry.get('enclosures', []) if 'torrent' in e.type
            ]:
                self.download(enclosure)
                break   # the first one is enough!

    def download(self, enclosure):
        dest = enclosure.href.split('/')[-1]
        if not dest.endswith('.torrent'):
            dest += '.torrent'
        destfile = self.path(dest)
        self.log('* Downloading %s' % dest, 1)
        torrent = open(destfile, 'w')
        torrent.write(urllib.urlopen(enclosure.href).read())
        torrent.close()

if __name__ == '__main__':
    import optparse
    p = optparse.OptionParser(usage='Usage: %prog [options] <feed-url> [<filter-regex>...]')
    p.add_option('-d', '--dest-dir',
        help='save enclosures and the timestamps in DEST', metavar='DEST'
    )
    p.add_option('-f', '--force', action='store_true',
        help='redo entries that have already been seen'
    )
    p.add_option('-D', '--debug', type='int', help='set the logging level')
    p.add_option('-n', '--dry-run', action='store_true',
        help="don't download any enclosures or update timestamps"
    )
    p.set_defaults(dest_dir='.', force=False, debug=0, dry_run=False)
    opts, args = p.parse_args()
    if not args:
        p.error('Feed URL missing')
    f = RSSFetcher(opts)
    f.fetch(args[0], args[1:])
    f.close()
